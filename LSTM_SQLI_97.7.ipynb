{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_2jIlP5pMfr5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout,Embedding\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import mode\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-c_I5oBINwWs"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\moham\\OneDrive - The British University in Egypt\\Desktop\\Year 3\\Semester1\\GP\\datasets\\clean_sql_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4jiUoQD-PFBb"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df['Query'])\n",
    "\n",
    "# Convert text to sequences\n",
    "X = tokenizer.texts_to_sequences(df['Query'])\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "X = pad_sequences(X, maxlen=100)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['Label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uZnD9MRpkWma"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                â”‚ ?                           â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          â”‚ ?                           â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        â”‚ ?                           â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                â”‚ ?                           â”‚     \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          â”‚ ?                           â”‚     \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                        â”‚ ?                           â”‚     \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "model_lstm.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KYlSoTZnkWoV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1484/1484\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 83ms/step - accuracy: 0.9492 - loss: 0.1577 - val_accuracy: 0.9803 - val_loss: 0.0691\n",
      "Epoch 2/5\n",
      "\u001b[1m1484/1484\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 90ms/step - accuracy: 0.9819 - loss: 0.0613 - val_accuracy: 0.9807 - val_loss: 0.0647\n",
      "Epoch 3/5\n",
      "\u001b[1m1484/1484\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 90ms/step - accuracy: 0.9839 - loss: 0.0531 - val_accuracy: 0.9812 - val_loss: 0.0689\n",
      "Epoch 4/5\n",
      "\u001b[1m1484/1484\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 93ms/step - accuracy: 0.9879 - loss: 0.0373 - val_accuracy: 0.9780 - val_loss: 0.0779\n",
      "Epoch 5/5\n",
      "\u001b[1m1484/1484\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 94ms/step - accuracy: 0.9893 - loss: 0.0320 - val_accuracy: 0.9803 - val_loss: 0.0765\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model_lstm.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EBVGSQK5kWqC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m928/928\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.9797 - loss: 0.0779\n",
      "Test Accuracy: 0.9798\n",
      "\u001b[1m928/928\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step\n",
      "\n",
      "ğŸ“Œ LSTM Model Evaluation:\n",
      "âœ… LSTM Accuracy: 0.9798\n",
      "âœ… LSTM Precision: 0.9889\n",
      "âœ… LSTM Recall: 0.9724\n",
      "âœ… LSTM F1-score: 0.9805\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model_lstm.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_lstm = model_lstm.predict(X_test)\n",
    "y_pred_lstm = (y_pred_lstm > 0.5).astype(int)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy_lstm = accuracy_score(y_test, y_pred_lstm)\n",
    "precision_lstm = precision_score(y_test, y_pred_lstm)\n",
    "recall_lstm = recall_score(y_test, y_pred_lstm)\n",
    "f1_lstm = f1_score(y_test, y_pred_lstm)\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nğŸ“Œ LSTM Model Evaluation:\")\n",
    "print(f\"âœ… LSTM Accuracy: {accuracy_lstm:.4f}\")\n",
    "print(f\"âœ… LSTM Precision: {precision_lstm:.4f}\")\n",
    "print(f\"âœ… LSTM Recall: {recall_lstm:.4f}\")\n",
    "print(f\"âœ… LSTM F1-score: {f1_lstm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HRVlC1VvkWrp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tokenizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the tokenizer\n",
    "joblib.dump(tokenizer, 'tokenizer.pkl')\n",
    "print(\"âœ… Tokenizer saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tmoGc5AvkV7O"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LSTM model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the LSTM model\n",
    "model_lstm.save('lstm_model.h5')\n",
    "print(\"âœ… LSTM model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step\n",
      "Prediction: Malicious SQL Injection\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def predict_sql_injection_lstm(query):\n",
    "    \"\"\"\n",
    "    Loads the saved LSTM model and tokenizer to predict if a query is malicious.\n",
    "    \"\"\"\n",
    "    # Load the saved tokenizer\n",
    "    tokenizer = joblib.load('tokenizer.pkl')\n",
    "    model_lstm = load_model('lstm_model.h5')\n",
    "\n",
    "    query_sequence = tokenizer.texts_to_sequences([query])\n",
    "    query_padded = pad_sequences(query_sequence, maxlen=100)\n",
    "\n",
    "    # Predict (0 = Benign, 1 = Malicious)\n",
    "    prediction = model_lstm.predict(query_padded)[0][0]\n",
    "    \n",
    "    # Return the classification result\n",
    "    return \"Malicious SQL Injection\" if prediction > 0.5 else \"Benign Query\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step\n",
      "Prediction: Malicious SQL Injection\n"
     ]
    }
   ],
   "source": [
    "query_lstm = \"45017c or DROP table users\"\n",
    "result_lstm = predict_sql_injection_lstm(query_lstm)\n",
    "print(f\"Prediction: {result_lstm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tokenizer is saved.\n",
      "âœ… LSTM model is saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if the tokenizer is saved\n",
    "if os.path.exists(\"tokenizer.pkl\"):\n",
    "    print(\"âœ… Tokenizer is saved.\")\n",
    "\n",
    "# Check if the LSTM model is saved\n",
    "if os.path.exists(\"lstm_model.h5\"):\n",
    "    print(\"âœ… LSTM model is saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the LSTM model\n",
    "model_lstm = load_model('lstm_model.h5')\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = joblib.load('tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess for RF and SVM\n",
    "X_test_tfidf = vectorizer.transform(df['Query'])\n",
    "\n",
    "# Preprocess for LSTM\n",
    "X_test_sequences = tokenizer.texts_to_sequences(df['Query'])\n",
    "\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4636/4636\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 37ms/step\n"
     ]
    }
   ],
   "source": [
    "# RF predictions (probabilities)\n",
    "y_pred_rf = model_rf.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "# SVM predictions (probabilities)\n",
    "y_pred_svm = model_svm.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "# LSTM predictions (probabilities)\n",
    "y_pred_lstm = model_lstm.predict(X_test_padded).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine predictions into a new dataset\n",
    "meta_features = np.column_stack((y_pred_rf, y_pred_svm, y_pred_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Train the meta-model\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(meta_features, df['Label'])  # df['Label'] is the true labels\n",
    "\n",
    "# Make final predictions\n",
    "final_predictions = meta_model.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Evaluation:\n",
      "Accuracy: 0.9954\n",
      "Precision: 0.9979\n",
      "Recall: 0.9933\n",
      "F1-score: 0.9956\n"
     ]
    }
   ],
   "source": [
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(df['Label'], final_predictions)\n",
    "precision = precision_score(df['Label'], final_predictions)\n",
    "recall = recall_score(df['Label'], final_predictions)\n",
    "f1 = f1_score(df['Label'], final_predictions)\n",
    "\n",
    "print(f\"Ensemble Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ensemble model, tokenizer, and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the meta-model (e.g., Logistic Regression)\n",
    "joblib.dump(meta_model, 'ensemble_model.pkl')\n",
    "\n",
    "# Save the tokenizer and vectorizer\n",
    "joblib.dump(tokenizer, 'tokenizer.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "\n",
    "print(\"âœ… Ensemble model, tokenizer, and vectorizer saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVTsqOUY-5R-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-JpKiyI01u-y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WATYgr9s1vBS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5TSSUVL1vDk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HH6j7X1c1vF2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQ5-oOyp1vIN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7vvExMs71vKX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PvL-45L1vMt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPY3dV3Z1vPX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tjsofs8H1vRp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkMn7sTG1vTx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohaV1oTy1vWT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBN4GIJs1vYZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hljHxvxl1vax"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
